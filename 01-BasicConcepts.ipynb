{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import siibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first off, update siibra to latest release\n",
    "!pip install -U siibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra\n",
    "from packaging.version import Version\n",
    "assert Version(siibra.__version__) >= Version('1.0a08')\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We populate the cache with common data items here, so we need not wait later on.\n",
    "# This is not usually needed - siibra fetches data only as needed.\n",
    "with siibra.QUIET:\n",
    "    siibra.warm_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing brain parcellations\n",
    "\n",
    "Preconfigured reference parcellations are stored in the instance table `siibra.parcellations`. \n",
    "The configuration is retrieved automatically from an github repository that we maintain with siibra.\n",
    "Instance table provide a tabular overview of their elements with the `dataframe` function, which returns a [pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) - a rich object with functions similar to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siibra.parcellations.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements in an instance table can be accessed in a couple of ways, in particular\n",
    "\n",
    " - by iterating over all instances\n",
    " - by fuzzy matching of keyword or name with the index operator `[.]` or the `get()` method\n",
    " - by tab-completion\n",
    "\n",
    "Let's use keyword matching to retrieve the most recent Julich Brain parcellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julichbrain = siibra.parcellations.get('julich')\n",
    "julichbrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an instance table of atlases, which we could use to access the parcellations linked with the human atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siibra.atlases.get('human').parcellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at some metadata\n",
    "print(f\"Name:     {julichbrain.name}\")\n",
    "print(f\"Id:       {julichbrain.id}\")\n",
    "print(f\"Modality: {julichbrain.modality}\\n\")\n",
    "print(f\"{julichbrain.description}\\n\")\n",
    "for p in julichbrain.publications:\n",
    "    print(p['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting parcellation is a semantic object. It represents the region hierarchy of the parcellation.\n",
    "We can find regions by name using the `find` function. If we know unique keywords and expect a single match, we can also use `get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in julichbrain.find('v1'):\n",
    "    print(region.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, areas often appear three times: Julich-Brain defines them separately for the left and right hemisphere, and additionally defines a common parent region. In fact the parent object represents the corresponding subtree. We can more easily access individual regions by using `get_region` instead of `find_regions`. This method assumes the region specification is unique, and either returns a single region object or fails. If it finds multiple matches, it will try if they have a common parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the whole amygdala subtree\n",
    "julichbrain.get_region('v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may output the subtree anchored at a given region, if any, using `Region.tree2str()`. This is useful to inspect a region object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = julichbrain.get_region('occipital cortex')\n",
    "print(occ.tree2str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing parcellation maps\n",
    "\n",
    "A parcellation map or region map is a spatial object corresponding to a parcellation. \n",
    "We can access maps with the `get_map` function of parcellation objects.\n",
    "Since parcellations may provide maps in different spaces, `siibra` expects you to specify the space. \n",
    "Note: Preconfigured reference spaces are managed in another instance table - `siibra.spaces` (you might have guessed it). \n",
    "\n",
    "\n",
    "Let's access the maximum probability map of Julich-Brain in the MNI152 space to see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julich_mpm = julichbrain.get_map(space=siibra.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "mpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the actual image of a parcellation map\n",
    "The returned map provides all information required to fetch the actual image.\n",
    "To access it we need to retrieve the actual data using the `fetch()` method, which returns a Nifti1Image object.\n",
    "This step is separate for two reasons:\n",
    "- The parcellation map is more than just the image - it provides information about the space and parcellation of the map, and possibly multiple resource where the data is stored.\n",
    "- `siibra` uses a lazy strategy for data loading. `fetch` is the typical last step to actually retrieve the underlying content.\n",
    "\n",
    "We can use the wonderful `nilearn` library for plotting the map. It plots in the MNI152 space by default, so as long as we work in this space plotting is simple enough.\n",
    "\n",
    "Some parcellations (and other 3D volumes) are split into multiple fragments represented in separate image volumes. For Julich-Brain 2.9, each hemisphere is in a different fragment. We can fetch individual fragments, but if no fragment is specified, siibra will merge the available ones into a single volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "cmap = julich_mpm.get_colormap()\n",
    "plotting.plot_roi(julich_mpm.fetch(), cmap=cmap, title=julich_mpm.parcellation.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching probability maps\n",
    "\n",
    "Julich-Brain, like some other parcellations, is a probabilistic parcellation. The labelled volumes in the maximum probability map (mpm) above are only a summary representation, displaying for each voxel the brain region of highest probability. \n",
    "Each region is additionally available as a probability map, which provides statistical information in the reference space for each particular region.\n",
    "\n",
    "We received the labelled volumes above because `siibra` uses labelled volumes as the default map type. \n",
    "To retrieve probability maps, we explicitly request `siibra.MapType.STATISTICAL` as maptype from the parcellation.\n",
    "It returns a sparse map representation, since the set of all probability maps contains several 100 of NIfTI volumes with mostly empty voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julich_pmaps = julichbrain.get_map(\n",
    "    space=siibra.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC,\n",
    "    maptype=siibra.MapType.STATISTICAL\n",
    ")\n",
    "julich_pmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the probability maps, we will call fetch again. However, this time, we need to specify a region.\n",
    "The sparse representation will then generate a (dense) Nifti1Image which we can use as expected.\n",
    "Plotting of probability maps works nicely with nilearn's `plot_stat_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = julich_pmaps.fetch(region='hoc5 right')\n",
    "plotting.plot_stat_map(pmap, title=f'hOc5 right of {julich_pmaps.parcellation.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background, `siibra` uses an index to identify regions in a parcellation map.\n",
    "The index informs about the image volume and the label used to map the region.\n",
    "Usually we don't need to, but we can request and use these indices as well for fetching.\n",
    "We will see that a region in the probability map is indexed by the volume, not by a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = julich_pmaps.get_index(region='hoc5 right')\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is different if we request the index of the same region in the maximum probability map, which is a labelled parcellation and represents all regions by their voxel label in the same volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = julich_mpm.get_index(region='hoc5 right')\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, while not recommended, we can also use this index to fetch from the map instead of using a region or region name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = julich_pmaps.fetch(index=index)\n",
    "plotting.plot_stat_map(pmap, title=f'hOc5 right of {julich_pmaps.parcellation.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we request a specific region when fetching from the labelled map, `siibra` will construct a binary mask of the region. This is different in shape from the probabilistic maps, but of course sits at the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = julich_mpm.fetch(region='hoc5 right')\n",
    "plotting.plot_roi(mask, title=f'hOc5 right of {julich_pmaps.parcellation.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting volumes of interest from high resolution\n",
    "\n",
    "Accessing image volumes is at the heart of `siibra`, and also works for high resolution images such as the BigBrain model. \n",
    "\n",
    "BigBrain is a reference space in `siibra`, and the corresponding image is the template of that space.\n",
    "Getting a template from a space corresonds to getting the map of a parcellation - we call the `get_template` method of the space object.\n",
    "\n",
    "To get access to the image data of the template, we use `fetch` again on the template object.\n",
    "However, fetching BigBrain at full resolution is not a good idea - it is a 1TByte dataset. \n",
    "`siibra` will therefore by default fetch a downscaled version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrain = siibra.spaces.get('bigbrain').get_template()\n",
    "bigbrain_img = bigbrain.fetch()\n",
    "plotting.plot_img(bigbrain_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we request the full resolution, `siibra` will complain and choose a larger but feasible resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrain.fetch(resolution_mm=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with full resolution data, we typically fetch volumes of interest only.\n",
    "`siibra` represents these as bounding boxes (`siibra.locations.BoundingBox`).\n",
    "Bounding boxes are one type of locations provided by `siibra`, and all locations are uniquely associated to a reference space.\n",
    "We construct a bounding box in BigBrain space by using the min and max point (-3.979, -61.256, 3.906) and (5.863, -55.356, -2.487):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voi = siibra.locations.BoundingBox(\n",
    "    (-3.979, -61.256, 3.906),\n",
    "    (5.863, -55.356, -2.487),\n",
    "    space='bigbrain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bounding box can be used to fetch a full resolution chunk from BigBrain.\n",
    "To look around in the chunk, nilearn's `view_img` is nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrainchunk = bigbrain.fetch(resolution_mm=-1, voi=voi)\n",
    "plotting.view_img(bigbrainchunk, bg_img=None, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting image chunk sits properly in its reference space, so we can also plot it on top of the low-resolution whole brain image that we fetched already above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(bigbrainchunk, bg_img=bigbrain_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same bounding box to extract chunks from other objects in the same space, like parcellation maps. \n",
    "Here we use the cortical layer maps in BigBrain space (in labelled map format), and download them in full resolution.\n",
    "For the superimposition, we can use `view_img` with reduced `opacity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layermap = siibra.parcellations.get('cortical layers').get_map(space='bigbrain')\n",
    "mask = layermap.fetch(resolution_mm=0.16, voi=voi, fragment='left')\n",
    "plotting.view_img(mask, bg_img=bigbrainchunk, opacity=.1, symmetric_cmap=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6134497cd5410b1b275ebc88f99d14855849379b696eb9e04cff5dd9aa5e77a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
