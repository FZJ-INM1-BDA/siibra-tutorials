{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054068bc-bf8d-4ce5-8e45-ad57bc3bf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ac553-8eaa-4690-a032-cfc9f0bd6916",
   "metadata": {},
   "source": [
    "# Define region of interest map\n",
    "\n",
    "Here we define a region of interest by annotation a point in BigBrain space, and building a heatmap volume of the point with a certain uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c2631-a495-43d9-81a8-25d90080c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = siibra.from_json(\"\"\"\n",
    "{\n",
    "  \"@id\": \"2343bfd0\",\n",
    "  \"@type\": \"https://openminds.ebrains.eu/sands/CoordinatePoint\",\n",
    "  \"coordinateSpace\": {\n",
    "    \"@id\": \"minds/core/referencespace/v1.0.0/a1655b99-82f1-420f-a3c2-fe80fd4c8588\"\n",
    "  },\n",
    "  \"coordinates\": [\n",
    "    {\n",
    "      \"@id\": \"81c7e0f0\",\n",
    "      \"@type\": \"https://openminds.ebrains.eu/core/QuantitativeValue\",\n",
    "      \"value\": -44.36846,\n",
    "      \"unit\": {\n",
    "        \"@id\": \"id.link/mm\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"@id\": \"b8f02fa8\",\n",
    "      \"@type\": \"https://openminds.ebrains.eu/core/QuantitativeValue\",\n",
    "      \"value\": 4.32578,\n",
    "      \"unit\": {\n",
    "        \"@id\": \"id.link/mm\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"@id\": \"10217fd0\",\n",
    "      \"@type\": \"https://openminds.ebrains.eu/core/QuantitativeValue\",\n",
    "      \"value\": 30.56429,\n",
    "      \"unit\": {\n",
    "        \"@id\": \"id.link/mm\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74612f33-7488-4a95-8f24-ebd211d3239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the point to an image volume with uncertainty radius\n",
    "pc = siibra.PointCloud([pt], space='bigbrain', sigma_mm=0.3)\n",
    "query_volume = siibra.volumes.from_pointcloud(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407c69c-6211-464b-b621-15079a3b61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot this query volume on top of a lower-resolution copy of BigBrain\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "bigbrain = siibra.get_template('bigbrain').fetch()\n",
    "f = plt.figure(figsize=(13, 4))\n",
    "plotting.plot_stat_map(query_volume.fetch(), bg_img=bigbrain, cmap='viridis', figure=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bdd44-31c7-49f4-bdd1-8d53a0baab9f",
   "metadata": {},
   "source": [
    "# Sample cortical image patches inside query region\n",
    "\n",
    "The volume can be used to let siibra sample cortical patches from BigBrain 1 micron data.\n",
    "For this purpose, siibra samples vertices on the cortical midsurface close to the region of interest, and derives oriented patch bounding boxes using the layer surface geometry. \n",
    "The number of proposed patches depends on the size of the region of interest - larger heatmaps will result in more patches and longer runtimes for the query.\n",
    "The query can take some time, since siibra resamples image data into oriented patches.\n",
    "The resulting image objects come with spatial metadata that preserves their anchoring in the BigBrain space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a54651-4e1d-4d1c-99bc-587cf5a6d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run feature query for cortical patch extraction.\n",
    "# this can take a little, since suitable sample patches will be resampled into upright position.\n",
    "features = siibra.features.get(query_volume, siibra.features.cellular.BigBrain1MicronPatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150dc553-31cf-4732-ad66-4eb1081c84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the first of the resulting patches.\n",
    "assert len(features) > 0\n",
    "patch = features[0]\n",
    "patch_img = patch.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32377db-2338-43f2-98bb-1efd5bb188eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch layer mask for the patch\n",
    "layermaps = siibra.get_map('layers', space='bigbrain')\n",
    "voi = patch.get_boundingbox()\n",
    "layermask = layermaps.fetch(fragment='left', format='image', voi=voi, resolution_mm=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624171a-602e-41ac-8545-6405d6176850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the patch in 3D context as well as the corresponding layer mask.\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,6))\n",
    "plotting.plot_img(patch_img, bg_img=bigbrain, display_mode='tiled', axes=ax1)\n",
    "plotting.plot_img(patch_img, bg_img=None, display_mode='y', cmap='gray', axes=ax2, cut_coords=[voi.minpoint[1]])\n",
    "plotting.plot_img(layermask, bg_img=None, display_mode='y', cmap='Set1', axes=ax3, cut_coords=[voi.minpoint[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6844961-31a9-48e6-a9f9-346cb73401b1",
   "metadata": {},
   "source": [
    "# Use an AI model to detect cells in the patch\n",
    "\n",
    "We use a pre-trained Contour Proposal Network (Eric Upschulte et al.) from celldetection.org to segment cell bodies in the resulting patch image.\n",
    "For this, we reformat the patch into a 3-channel float image.\n",
    "To reduce runtime and memory needs of this notebook, we limit the extraction to a subwindow in side the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4947459-626f-47ac-9f7a-b373bf54492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format into 3-channel 2D-image for cell detection\n",
    "import numpy as np\n",
    "img2D = patch_img.get_fdata().squeeze()[2100:2900, :500] / 2**16\n",
    "img2D_3ch = np.stack((img2D,) * 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ad496-105e-4eba-a5ad-b5317c6bc2ae",
   "metadata": {},
   "source": [
    "## Variant 1: Run the model on HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7249c-73a6-4ad0-b995-f0479bc58c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the detection on HuggingFace.\n",
    "# For this, store image to temporary file.\n",
    "from gradio_client import Client, handle_file\n",
    "client = Client(\"ericup/celldetection\")\n",
    "plt.imsave(\"tmp.png\", (img2D_3ch * 255).astype('uint8'), )\n",
    "result = client.predict(\n",
    "    filename=handle_file(\"tmp.png\"),\n",
    "    model=\"vacumu_CpnResNeXt101UNet-f33b2634bb51f299\",\n",
    "    enable_score_threshold=False,\n",
    "    enable_nms_threshold=False,\n",
    "    enable_samples=False,\n",
    "    use_label_channels=True,\n",
    "    api_name=\"/predict\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae564b-5f64-42b6-88ca-66c8774ad04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load overlay mask to visualize the result\n",
    "overlay_filename, img_filename, h5_filename, csv_filename = result\n",
    "overlay = plt.imread(overlay_filename)\n",
    "plt.imshow(img2D_3ch)\n",
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de53cbd-1b22-4b8c-92f5-30829a8dba5f",
   "metadata": {},
   "source": [
    "## Variant 2: Run CPN model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d17a18-a5fe-46b4-a20b-3f25d5932025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import celldetection as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe9662-babb-4567-a5a4-c6f7885b7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve CPN model for cell detection\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = cd.fetch_model('vacumu_CpnResNeXt101UNet-f33b2634bb51f299').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566426fe-18bd-46a8-832a-f44bd5da213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cell detection\n",
    "x = cd.to_tensor(img2D_3ch, transpose=True, device=device, dtype=torch.float32)\n",
    "x = x[None]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa4d27-3ac5-4cd5-b053-11508a5385e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the contours\n",
    "contours = y[\"contours\"][0].cpu().data.numpy()\n",
    "plt.figure()\n",
    "plt.imshow(img2D, cmap='gray')\n",
    "for c in contours:\n",
    "    X, Y = c.T\n",
    "    plt.plot(X, Y, '-', lw=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025895d-8f1d-436b-98cf-90df45fb6464",
   "metadata": {},
   "source": [
    "# Published cell densities\n",
    "\n",
    "Siibra has access to published datasets with layerwise cell densities, based on a similar workflow. These consist of 10 patches each for a selection of cytoarchitectonic brain areas. We obtain a list of the available data features by querying with the whole parcellation. We plot the first of them to get an impression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c952031-19c2-4e0c-b0ac-2689e52a4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with siibra.QUIET:\n",
    "    features = siibra.features.get(\n",
    "        siibra.parcellations.get('julich 3.1'), \n",
    "        siibra.features.cellular.LayerwiseCellDensity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a87e5-455b-4c41-a949-317132b999f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature contains a DataFrame with the measurements.\n",
    "features[0].plot()\n",
    "features[0].data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
